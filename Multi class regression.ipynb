{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n",
      "Cost after iteration 0: 2.302585\n",
      "Cost after iteration 50: 1.064157\n",
      "Cost after iteration 100: 0.777513\n",
      "Cost after iteration 150: 0.654461\n",
      "Cost after iteration 200: 0.584293\n",
      "Cost after iteration 250: 0.538023\n",
      "Cost after iteration 300: 0.504723\n",
      "Cost after iteration 350: 0.479314\n",
      "Cost after iteration 400: 0.459100\n",
      "Cost after iteration 450: 0.442509\n",
      "Cost after iteration 500: 0.428558\n",
      "Cost after iteration 550: 0.416599\n",
      "Cost after iteration 600: 0.406185\n",
      "Cost after iteration 650: 0.396998\n",
      "Cost after iteration 700: 0.388804\n",
      "Cost after iteration 750: 0.381428\n",
      "Cost after iteration 800: 0.374734\n",
      "Cost after iteration 850: 0.368617\n",
      "Cost after iteration 900: 0.362994\n",
      "Cost after iteration 950: 0.357796\n",
      "Cost after iteration 1000: 0.352968\n",
      "Cost after iteration 1050: 0.348464\n",
      "Cost after iteration 1100: 0.344248\n",
      "Cost after iteration 1150: 0.340286\n",
      "Cost after iteration 1200: 0.336551\n",
      "Cost after iteration 1250: 0.333022\n",
      "Cost after iteration 1300: 0.329676\n",
      "Cost after iteration 1350: 0.326498\n",
      "Cost after iteration 1400: 0.323473\n",
      "Cost after iteration 1450: 0.320586\n",
      "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n",
      "Train accuracy: {} % 91.52\n",
      "Test accuracy: {} % 91.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x226272cc240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the example is  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2262a2e9a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for opencv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9153e155a845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-9153e155a845>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frame\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Contours\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import input_data\n",
    "import cv2\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def main():\n",
    "    mnist = input_data.read_data_sets(\"/temp/data/\",one_hot=False)\n",
    "    data = mnist.train.next_batch(5000)\n",
    "    train_x = data[0]\n",
    "    Y = data[1]\n",
    "    train_y = (np.arange(np.max(Y) + 1) == Y[:, None]).astype(int)\n",
    "    # 0.00002-92\n",
    "    # 0.000005-92, 93 when 200000 190500\n",
    "\n",
    "    d = model(train_x.T, train_y.T, Y, num_iters=1500, alpha=0.05, print_cost=True)\n",
    "    w_from_model = d[\"w\"]\n",
    "    b_from_model = d[\"b\"]\n",
    "    print(\"Ready for opencv\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img, contours, thresh = get_img_contour_thresh(img)\n",
    "        ans=''\n",
    "        if len(contours) > 0:\n",
    "            contour = max(contours, key=cv2.contourArea)\n",
    "            if cv2.contourArea(contour) > 2500:\n",
    "                # print(predict(w_from_model,b_from_model,contour))\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                #newImage = thresh[y - 15:y + h + 15, x - 15:x + w +15]\n",
    "                newImage = thresh[y :y + h, x:x + w]\n",
    "                newImage = cv2.resize(newImage, (28, 28))\n",
    "                newImage=np.array(newImage)\n",
    "                newImage=newImage.flatten()\n",
    "                newImage=newImage.reshape(newImage.shape[0],1)\n",
    "                ans=predict(w_from_model, b_from_model, newImage)\n",
    "\n",
    "        x, y, w, h = 0, 0, 300, 300\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(img, \"Predicted Value is \"+str(ans), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        cv2.imshow(\"Contours\", thresh)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "# Logistic Regression as deep learning\n",
    "\n",
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return img, contours, thresh1\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z), axis=1))\n",
    "    return sm\n",
    "\n",
    "\n",
    "def initialize(dim1, dim2):\n",
    "    \"\"\"\n",
    "    :param dim: size of vector w initilazied with zeros\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    w = np.zeros(shape=(dim1, dim2))\n",
    "    b = np.zeros(shape=(10, 1))\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    :param w: weights for w\n",
    "    :param b: bias\n",
    "    :param X: size of data(no of features, no of examples)\n",
    "    :param Y: true label\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m = X.shape[1]  # getting no of rows\n",
    "\n",
    "    # Forward Prop\n",
    "    A = softmax((np.dot(w.T, X) + b).T)\n",
    "    cost = (-1 / m) * np.sum(Y * np.log(A))\n",
    "\n",
    "    # backwar prop\n",
    "    dw = (1 / m) * np.dot(X, (A - Y).T)\n",
    "    db = (1 / m) * np.sum(A - Y)\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    return grads, cost\n",
    "\n",
    "\n",
    "def optimize(w, b, X, Y, num_iters, alpha, print_cost=False):\n",
    "    \"\"\"\n",
    "    :param w: weights for w\n",
    "    :param b: bias\n",
    "    :param X: size of data(no of features, no of examples)\n",
    "    :param Y: true label\n",
    "    :param num_iters: number of iterations for gradient\n",
    "    :param alpha:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    costs = []\n",
    "    for i in range(num_iters):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "\n",
    "        # Record the costs\n",
    "        if i % 50 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 50 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    :param w:\n",
    "    :param b:\n",
    "    :param X:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # m = X.shape[1]\n",
    "    # y_pred = np.zeros(shape=(1, m))\n",
    "    # w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    y_pred = np.argmax(softmax((np.dot(w.T, X) + b).T), axis=0)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, Y, num_iters, alpha, print_cost):\n",
    "    \"\"\"\n",
    "    :param X_train:\n",
    "    :param Y_train:\n",
    "    :param X_test:\n",
    "    :param Y_test:\n",
    "    :param num_iterations:\n",
    "    :param learning_rate:\n",
    "    :param print_cost:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    w, b = initialize(X_train.shape[0], Y_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iters, alpha, print_cost)\n",
    "\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    mnist = input_data.read_data_sets(\"/temp/data/\",one_hot=False)\n",
    "    tb = mnist.train.next_batch(200)\n",
    "    Y_test = tb[1]\n",
    "    X_test = tb[0]\n",
    "    y_prediction_train = predict(w, b, X_train)\n",
    "    y_prediction_test = predict(w, b, X_test.T)\n",
    "    print(\"Train accuracy: {} %\", sum(y_prediction_train == Y) / (float(len(Y))) * 100)\n",
    "    print(\"Test accuracy: {} %\", sum(y_prediction_test == Y_test) / (float(len(Y_test))) * 100)\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": y_prediction_test,\n",
    "         \"Y_prediction_train\": y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": alpha,\n",
    "         \"num_iterations\": num_iters}\n",
    "\n",
    "    # Plot learning curve (with costs)\n",
    "    costs = np.squeeze(d['costs'])\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "    plt.plot()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    pri(X_test, y_prediction_test)\n",
    "    return d\n",
    "\n",
    "\n",
    "def pri(X_test, y_prediction_test):\n",
    "    time.sleep(5)\n",
    "    example = X_test[2, :]\n",
    "    print(\"Prediction for the example is \", y_prediction_test[2])\n",
    "    plt.imshow(np.reshape(example, [28, 28]))\n",
    "    plt.plot()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
